{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Convolutional Layers\n",
    "\n",
    "### Nhung Le\n",
    "\n",
    "### Goals:\n",
    "- Understand Convolution layers \n",
    "- Implement them using PyTorch."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question:** What is a convolution operation?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import common dependencies\n",
    "import torch\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available==True:\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolution Demo\n",
    "\n",
    "https://cs231n.github.io/convolutional-networks/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Input: $W_{input}$ x $H_{input}$ x $D_input$\n",
    "- Hyperparameters:\n",
    "    - Number of filters: K\n",
    "    - Spatial extent: F\n",
    "    - Stride: S\n",
    "    - Amount of zero padding: P\n",
    "- Output:\n",
    "    - $W_{output} = (W_{input} - F + 2P)/S + 1$ \n",
    "    - $H_{output}$ = $(H_{input} - F + 2P)/S + 1$\n",
    "    - $D_{output} = K$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_n_params(model):\n",
    "    return sum(p.numel() for p in model.parameters())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1D Convolutions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Question: What would be the desired input shape for the 1D Convolution layer?\n",
    "desired_shape = (3, 10)\n",
    "\n",
    "#Generate a random tensor of the desired shape\n",
    "x_1d = torch.rand(desired_shape).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Knowing the module and its attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mInit signature:\u001b[0m\n",
       "\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mConv1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0min_channels\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mout_channels\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mkernel_size\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTuple\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mstride\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTuple\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mpadding\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTuple\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mdilation\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTuple\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mgroups\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mbias\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mpadding_mode\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'zeros'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mDocstring:\u001b[0m     \n",
       "Applies a 1D convolution over an input signal composed of several input\n",
       "planes.\n",
       "\n",
       "In the simplest case, the output value of the layer with input size\n",
       ":math:`(N, C_{\\text{in}}, L)` and output :math:`(N, C_{\\text{out}}, L_{\\text{out}})` can be\n",
       "precisely described as:\n",
       "\n",
       ".. math::\n",
       "    \\text{out}(N_i, C_{\\text{out}_j}) = \\text{bias}(C_{\\text{out}_j}) +\n",
       "    \\sum_{k = 0}^{C_{in} - 1} \\text{weight}(C_{\\text{out}_j}, k)\n",
       "    \\star \\text{input}(N_i, k)\n",
       "\n",
       "where :math:`\\star` is the valid `cross-correlation`_ operator,\n",
       ":math:`N` is a batch size, :math:`C` denotes a number of channels,\n",
       ":math:`L` is a length of signal sequence.\n",
       "\n",
       "This module supports :ref:`TensorFloat32<tf32_on_ampere>`.\n",
       "\n",
       "* :attr:`stride` controls the stride for the cross-correlation, a single\n",
       "  number or a one-element tuple.\n",
       "\n",
       "* :attr:`padding` controls the amount of implicit zero-paddings on both sides\n",
       "  for :attr:`padding` number of points.\n",
       "\n",
       "* :attr:`dilation` controls the spacing between the kernel points; also\n",
       "  known as the à trous algorithm. It is harder to describe, but this `link`_\n",
       "  has a nice visualization of what :attr:`dilation` does.\n",
       "\n",
       "* :attr:`groups` controls the connections between inputs and outputs.\n",
       "  :attr:`in_channels` and :attr:`out_channels` must both be divisible by\n",
       "  :attr:`groups`. For example,\n",
       "\n",
       "    * At groups=1, all inputs are convolved to all outputs.\n",
       "    * At groups=2, the operation becomes equivalent to having two conv\n",
       "      layers side by side, each seeing half the input channels,\n",
       "      and producing half the output channels, and both subsequently\n",
       "      concatenated.\n",
       "    * At groups= :attr:`in_channels`, each input channel is convolved with\n",
       "      its own set of filters,\n",
       "      of size\n",
       "      :math:`\\left\\lfloor\\frac{out\\_channels}{in\\_channels}\\right\\rfloor`.\n",
       "\n",
       "Note:\n",
       "\n",
       "    Depending of the size of your kernel, several (of the last)\n",
       "    columns of the input might be lost, because it is a valid\n",
       "    `cross-correlation`_, and not a full `cross-correlation`_.\n",
       "    It is up to the user to add proper padding.\n",
       "\n",
       "Note:\n",
       "\n",
       "    When `groups == in_channels` and `out_channels == K * in_channels`,\n",
       "    where `K` is a positive integer, this operation is also termed in\n",
       "    literature as depthwise convolution.\n",
       "\n",
       "    In other words, for an input of size :math:`(N, C_{in}, L_{in})`,\n",
       "    a depthwise convolution with a depthwise multiplier `K`, can be constructed by arguments\n",
       "    :math:`(C_\\text{in}=C_{in}, C_\\text{out}=C_{in} \\times K, ..., \\text{groups}=C_{in})`.\n",
       "\n",
       "Note:\n",
       "    In some circumstances when using the CUDA backend with CuDNN, this operator\n",
       "    may select a nondeterministic algorithm to increase performance. If this is\n",
       "    undesirable, you can try to make the operation deterministic (potentially at\n",
       "    a performance cost) by setting ``torch.backends.cudnn.deterministic =\n",
       "    True``.\n",
       "    Please see the notes on :doc:`/notes/randomness` for background.\n",
       "\n",
       "\n",
       "Args:\n",
       "    in_channels (int): Number of channels in the input image\n",
       "    out_channels (int): Number of channels produced by the convolution\n",
       "    kernel_size (int or tuple): Size of the convolving kernel\n",
       "    stride (int or tuple, optional): Stride of the convolution. Default: 1\n",
       "    padding (int or tuple, optional): Zero-padding added to both sides of\n",
       "        the input. Default: 0\n",
       "    padding_mode (string, optional): ``'zeros'``, ``'reflect'``,\n",
       "        ``'replicate'`` or ``'circular'``. Default: ``'zeros'``\n",
       "    dilation (int or tuple, optional): Spacing between kernel\n",
       "        elements. Default: 1\n",
       "    groups (int, optional): Number of blocked connections from input\n",
       "        channels to output channels. Default: 1\n",
       "    bias (bool, optional): If ``True``, adds a learnable bias to the\n",
       "        output. Default: ``True``\n",
       "\n",
       "Shape:\n",
       "    - Input: :math:`(N, C_{in}, L_{in})`\n",
       "    - Output: :math:`(N, C_{out}, L_{out})` where\n",
       "\n",
       "      .. math::\n",
       "          L_{out} = \\left\\lfloor\\frac{L_{in} + 2 \\times \\text{padding} - \\text{dilation}\n",
       "                    \\times (\\text{kernel\\_size} - 1) - 1}{\\text{stride}} + 1\\right\\rfloor\n",
       "\n",
       "Attributes:\n",
       "    weight (Tensor): the learnable weights of the module of shape\n",
       "        :math:`(\\text{out\\_channels},\n",
       "        \\frac{\\text{in\\_channels}}{\\text{groups}}, \\text{kernel\\_size})`.\n",
       "        The values of these weights are sampled from\n",
       "        :math:`\\mathcal{U}(-\\sqrt{k}, \\sqrt{k})` where\n",
       "        :math:`k = \\frac{groups}{C_\\text{in} * \\text{kernel\\_size}}`\n",
       "    bias (Tensor):   the learnable bias of the module of shape\n",
       "        (out_channels). If :attr:`bias` is ``True``, then the values of these weights are\n",
       "        sampled from :math:`\\mathcal{U}(-\\sqrt{k}, \\sqrt{k})` where\n",
       "        :math:`k = \\frac{groups}{C_\\text{in} * \\text{kernel\\_size}}`\n",
       "\n",
       "Examples::\n",
       "\n",
       "    >>> m = nn.Conv1d(16, 33, 3, stride=2)\n",
       "    >>> input = torch.randn(20, 16, 50)\n",
       "    >>> output = m(input)\n",
       "\n",
       ".. _cross-correlation:\n",
       "    https://en.wikipedia.org/wiki/Cross-correlation\n",
       "\n",
       ".. _link:\n",
       "    https://github.com/vdumoulin/conv_arithmetic/blob/master/README.md\n",
       "\u001b[0;31mInit docstring:\u001b[0m Initializes internal Module state, shared by both nn.Module and ScriptModule.\n",
       "\u001b[0;31mFile:\u001b[0m           ~/opt/anaconda3/lib/python3.7/site-packages/torch/nn/modules/conv.py\n",
       "\u001b[0;31mType:\u001b[0m           type\n",
       "\u001b[0;31mSubclasses:\u001b[0m     \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "?nn.Conv1d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we create a Convolution layer and see how that works, let's understand what parameters does our 1D convolution layer need and what would be the expected output?\n",
    "\n",
    "### Questions\n",
    "- Input channels?\n",
    "- Output channels?\n",
    "- Kernel/Filter Size?\n",
    "- Stride?\n",
    "- Padding?\n",
    "\n",
    "https://towardsdatascience.com/intuitively-understanding-convolutions-for-deep-learning-1f6f42faee1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Instantiate a 1D Convolution Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv1d_layer = nn.Conv1d(in_channels= 3,  #Input channels\n",
    "                         out_channels= 5, #Output channels\n",
    "                         kernel_size=3, #Kernel/Filter size\n",
    "                         stride= 1, #Stride\n",
    "                         padding= 1, #Padding; In this case it's zero padding\n",
    "                         bias= True\n",
    "                        ) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Number of Parameters in the Convolution Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of parameters in our conv1d_layer is: 50\n"
     ]
    }
   ],
   "source": [
    "print('Number of parameters in our conv1d_layer is: {}'.format(get_n_params(conv1d_layer)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_1d = conv1d_layer(x_1d.unsqueeze(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question: Shape of the output??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 5, 10])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_1d.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2D Convolutions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Question: What would be the desired input shape for the 2D Convolution layer?\n",
    "desired_shape = (3, 20, 10)\n",
    "\n",
    "#Generate a random tensor of the desired shape\n",
    "x_2d = torch.rand(desired_shape).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Knowing the module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mInit signature:\u001b[0m\n",
       "\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mConv2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0min_channels\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mout_channels\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mkernel_size\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTuple\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mstride\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTuple\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mpadding\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTuple\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mdilation\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTuple\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mgroups\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mbias\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mpadding_mode\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'zeros'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mDocstring:\u001b[0m     \n",
       "Applies a 2D convolution over an input signal composed of several input\n",
       "planes.\n",
       "\n",
       "In the simplest case, the output value of the layer with input size\n",
       ":math:`(N, C_{\\text{in}}, H, W)` and output :math:`(N, C_{\\text{out}}, H_{\\text{out}}, W_{\\text{out}})`\n",
       "can be precisely described as:\n",
       "\n",
       ".. math::\n",
       "    \\text{out}(N_i, C_{\\text{out}_j}) = \\text{bias}(C_{\\text{out}_j}) +\n",
       "    \\sum_{k = 0}^{C_{\\text{in}} - 1} \\text{weight}(C_{\\text{out}_j}, k) \\star \\text{input}(N_i, k)\n",
       "\n",
       "\n",
       "where :math:`\\star` is the valid 2D `cross-correlation`_ operator,\n",
       ":math:`N` is a batch size, :math:`C` denotes a number of channels,\n",
       ":math:`H` is a height of input planes in pixels, and :math:`W` is\n",
       "width in pixels.\n",
       "\n",
       "This module supports :ref:`TensorFloat32<tf32_on_ampere>`.\n",
       "\n",
       "* :attr:`stride` controls the stride for the cross-correlation, a single\n",
       "  number or a tuple.\n",
       "\n",
       "* :attr:`padding` controls the amount of implicit zero-paddings on both\n",
       "  sides for :attr:`padding` number of points for each dimension.\n",
       "\n",
       "* :attr:`dilation` controls the spacing between the kernel points; also\n",
       "  known as the à trous algorithm. It is harder to describe, but this `link`_\n",
       "  has a nice visualization of what :attr:`dilation` does.\n",
       "\n",
       "* :attr:`groups` controls the connections between inputs and outputs.\n",
       "  :attr:`in_channels` and :attr:`out_channels` must both be divisible by\n",
       "  :attr:`groups`. For example,\n",
       "\n",
       "    * At groups=1, all inputs are convolved to all outputs.\n",
       "    * At groups=2, the operation becomes equivalent to having two conv\n",
       "      layers side by side, each seeing half the input channels,\n",
       "      and producing half the output channels, and both subsequently\n",
       "      concatenated.\n",
       "    * At groups= :attr:`in_channels`, each input channel is convolved with\n",
       "      its own set of filters, of size:\n",
       "      :math:`\\left\\lfloor\\frac{out\\_channels}{in\\_channels}\\right\\rfloor`.\n",
       "\n",
       "The parameters :attr:`kernel_size`, :attr:`stride`, :attr:`padding`, :attr:`dilation` can either be:\n",
       "\n",
       "    - a single ``int`` -- in which case the same value is used for the height and width dimension\n",
       "    - a ``tuple`` of two ints -- in which case, the first `int` is used for the height dimension,\n",
       "      and the second `int` for the width dimension\n",
       "\n",
       "Note:\n",
       "\n",
       "     Depending of the size of your kernel, several (of the last)\n",
       "     columns of the input might be lost, because it is a valid `cross-correlation`_,\n",
       "     and not a full `cross-correlation`_.\n",
       "     It is up to the user to add proper padding.\n",
       "\n",
       "Note:\n",
       "\n",
       "    When `groups == in_channels` and `out_channels == K * in_channels`,\n",
       "    where `K` is a positive integer, this operation is also termed in\n",
       "    literature as depthwise convolution.\n",
       "\n",
       "    In other words, for an input of size :math:`(N, C_{in}, H_{in}, W_{in})`,\n",
       "    a depthwise convolution with a depthwise multiplier `K`, can be constructed by arguments\n",
       "    :math:`(in\\_channels=C_{in}, out\\_channels=C_{in} \\times K, ..., groups=C_{in})`.\n",
       "\n",
       "Note:\n",
       "    In some circumstances when using the CUDA backend with CuDNN, this operator\n",
       "    may select a nondeterministic algorithm to increase performance. If this is\n",
       "    undesirable, you can try to make the operation deterministic (potentially at\n",
       "    a performance cost) by setting ``torch.backends.cudnn.deterministic =\n",
       "    True``.\n",
       "    Please see the notes on :doc:`/notes/randomness` for background.\n",
       "\n",
       "\n",
       "Args:\n",
       "    in_channels (int): Number of channels in the input image\n",
       "    out_channels (int): Number of channels produced by the convolution\n",
       "    kernel_size (int or tuple): Size of the convolving kernel\n",
       "    stride (int or tuple, optional): Stride of the convolution. Default: 1\n",
       "    padding (int or tuple, optional): Zero-padding added to both sides of\n",
       "        the input. Default: 0\n",
       "    padding_mode (string, optional): ``'zeros'``, ``'reflect'``,\n",
       "        ``'replicate'`` or ``'circular'``. Default: ``'zeros'``\n",
       "    dilation (int or tuple, optional): Spacing between kernel elements. Default: 1\n",
       "    groups (int, optional): Number of blocked connections from input\n",
       "        channels to output channels. Default: 1\n",
       "    bias (bool, optional): If ``True``, adds a learnable bias to the\n",
       "        output. Default: ``True``\n",
       "\n",
       "Shape:\n",
       "    - Input: :math:`(N, C_{in}, H_{in}, W_{in})`\n",
       "    - Output: :math:`(N, C_{out}, H_{out}, W_{out})` where\n",
       "\n",
       "      .. math::\n",
       "          H_{out} = \\left\\lfloor\\frac{H_{in}  + 2 \\times \\text{padding}[0] - \\text{dilation}[0]\n",
       "                    \\times (\\text{kernel\\_size}[0] - 1) - 1}{\\text{stride}[0]} + 1\\right\\rfloor\n",
       "\n",
       "      .. math::\n",
       "          W_{out} = \\left\\lfloor\\frac{W_{in}  + 2 \\times \\text{padding}[1] - \\text{dilation}[1]\n",
       "                    \\times (\\text{kernel\\_size}[1] - 1) - 1}{\\text{stride}[1]} + 1\\right\\rfloor\n",
       "\n",
       "Attributes:\n",
       "    weight (Tensor): the learnable weights of the module of shape\n",
       "        :math:`(\\text{out\\_channels}, \\frac{\\text{in\\_channels}}{\\text{groups}},`\n",
       "        :math:`\\text{kernel\\_size[0]}, \\text{kernel\\_size[1]})`.\n",
       "        The values of these weights are sampled from\n",
       "        :math:`\\mathcal{U}(-\\sqrt{k}, \\sqrt{k})` where\n",
       "        :math:`k = \\frac{groups}{C_\\text{in} * \\prod_{i=0}^{1}\\text{kernel\\_size}[i]}`\n",
       "    bias (Tensor):   the learnable bias of the module of shape\n",
       "        (out_channels). If :attr:`bias` is ``True``,\n",
       "        then the values of these weights are\n",
       "        sampled from :math:`\\mathcal{U}(-\\sqrt{k}, \\sqrt{k})` where\n",
       "        :math:`k = \\frac{groups}{C_\\text{in} * \\prod_{i=0}^{1}\\text{kernel\\_size}[i]}`\n",
       "\n",
       "Examples:\n",
       "\n",
       "    >>> # With square kernels and equal stride\n",
       "    >>> m = nn.Conv2d(16, 33, 3, stride=2)\n",
       "    >>> # non-square kernels and unequal stride and with padding\n",
       "    >>> m = nn.Conv2d(16, 33, (3, 5), stride=(2, 1), padding=(4, 2))\n",
       "    >>> # non-square kernels and unequal stride and with padding and dilation\n",
       "    >>> m = nn.Conv2d(16, 33, (3, 5), stride=(2, 1), padding=(4, 2), dilation=(3, 1))\n",
       "    >>> input = torch.randn(20, 16, 50, 100)\n",
       "    >>> output = m(input)\n",
       "\n",
       ".. _cross-correlation:\n",
       "    https://en.wikipedia.org/wiki/Cross-correlation\n",
       "\n",
       ".. _link:\n",
       "    https://github.com/vdumoulin/conv_arithmetic/blob/master/README.md\n",
       "\u001b[0;31mInit docstring:\u001b[0m Initializes internal Module state, shared by both nn.Module and ScriptModule.\n",
       "\u001b[0;31mFile:\u001b[0m           ~/opt/anaconda3/lib/python3.7/site-packages/torch/nn/modules/conv.py\n",
       "\u001b[0;31mType:\u001b[0m           type\n",
       "\u001b[0;31mSubclasses:\u001b[0m     Conv2d, ConvBn2d\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "?nn.Conv2d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Instantiate a 2D Convolution Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv2d_layer = nn.Conv2d(in_channels= 3,  #Input channels\n",
    "                         out_channels= 5, #Output channels\n",
    "                         kernel_size=3, #Kernel/Filter size\n",
    "                         stride= 1, #Stride\n",
    "                         padding= 1, #Padding; In this case it's zero padding\n",
    "                         bias= True\n",
    "                        ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv2d_layer_1 = nn.Conv2d(in_channels= 3,  #Input channels\n",
    "                         out_channels= 5, #Output channels\n",
    "                         kernel_size=(6, 2), #Kernel/Filter size\n",
    "                         stride= (1, 1), #Stride\n",
    "                         padding=  (2, 1), #Padding; In this case it's zero padding\n",
    "                         bias= True\n",
    "                        ) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Number of Parameters in the Convolution Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of parameters in our conv2d_layer is: 140\n"
     ]
    }
   ],
   "source": [
    "print('Number of parameters in our conv2d_layer is: {}'.format(get_n_params(conv2d_layer)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 20, 10])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_2d.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Input:\n",
    "- N (batchsize) = 1\n",
    "- C = 3\n",
    "- H = 20\n",
    "- W = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = conv2d_layer(x_2d.unsqueeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "out1 = conv2d_layer_1(x_2d.unsqueeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question: Shape of the output??\n",
    "\n",
    "Ref: https://pytorch.org/docs/stable/generated/torch.nn.Conv2d.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 5, 20, 10])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "output: (N, C_out, H_out, W_out)\n",
    "- N = 1\n",
    "- C_out = 5\n",
    "- H_out = (H_in + 2 * padding[0] - dilation[0] * (kernelsize[0] - 1) - 1) / stride [0] + 1\n",
    "        = (20 + 2 * 1 - 1 * (3 - 1) - 1) / 1 + 1\n",
    "        = (19 + 1) = 20\n",
    " \n",
    "- W_out = (W_in + 2 * padding[1] - dilation[1] * (kernelsize[1] - 1) - 1) / stride [1] + 1\n",
    "        = (10 + 2 * 1 - 1 * (3-1) - 1) / 1 + 1\n",
    "        = (9 + 1) = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 20, 10])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_2d.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv2d_layer_1 = nn.Conv2d(in_channels= 3,  #Input channels\n",
    "                         out_channels= 5, #Output channels\n",
    "                         kernel_size=(6, 2), #Kernel/Filter size\n",
    "                         stride= (1, 1), #Stride\n",
    "                         padding=  (2, 1), #Padding; In this case it's zero padding\n",
    "                         bias= True\n",
    "                        ) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "output: (N, C_out, H_out, W_out)\n",
    "- N = 1\n",
    "- C_out = 5\n",
    "- H_out = (H_in + 2 * padding[0] - dilation[0] * (kernelsize[0] - 1) - 1) / stride [0] + 1\n",
    "        = (20 + 2 * 2 - 1 * (6 - 1) - 1) / 1 + 1\n",
    "        = (20 + 4 - 5 - 1) + 1 = 19\n",
    " \n",
    "- W_out = (W_in + 2 * padding[1] - dilation[1] * (kernelsize[1] - 1) - 1) / stride [1] + 1\n",
    "        = (10 + 2 * 1 - 1 * (2 - 1) - 1) / 1 + 1\n",
    "        = (10 + 2 - 1 - 1)/1 + 1 = 11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 5, 19, 11])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out1.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Coding a CNN model using Pytorch with MNIST Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size  = 28*28   # images are 28x28 pixels\n",
    "output_size = 10      # there are 10 classes\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST('data', train=True, download=True,\n",
    "                   transform=transforms.Compose([\n",
    "                       transforms.ToTensor(),\n",
    "                       transforms.Normalize((0.1307,), (0.3081,))\n",
    "                   ])),\n",
    "    batch_size=64, shuffle=True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST('data', train=False, transform=transforms.Compose([\n",
    "                       transforms.ToTensor(),\n",
    "                       transforms.Normalize((0.1307,), (0.3081,))\n",
    "                   ])),\n",
    "    batch_size=1000, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x432 with 12 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# show images\n",
    "plt.figure(figsize=(10, 6))\n",
    "for i in range(12):\n",
    "    plt.subplot(2, 6, i + 1)\n",
    "    image, _ = train_loader.dataset.__getitem__(i)\n",
    "    plt.imshow(image.squeeze().numpy())\n",
    "    plt.axis('off');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fully Connected Layers (i.e., Linear)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FC1Layer(nn.Module):\n",
    "    def __init__(self, input_size, num_hidden, output_size):\n",
    "        super(FC1Layer, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.network = nn.Sequential(\n",
    "            nn.Linear(input_size, num_hidden), \n",
    "            nn.ReLU(), \n",
    "#             nn.Linear(num_hidden, num_hidden), \n",
    "#             nn.ReLU(), \n",
    "            nn.Linear(num_hidden, output_size), \n",
    "            nn.LogSoftmax(dim=1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, self.input_size)\n",
    "        return self.network(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self, input_size, n_feature, output_size):\n",
    "        super(CNN, self).__init__()\n",
    "        self.n_feature = n_feature\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=n_feature, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(n_feature, n_feature, kernel_size=5)\n",
    "        self.fc1 = nn.Linear(n_feature*4*4, 50)\n",
    "        self.fc2 = nn.Linear(50, 10)\n",
    "        \n",
    "    def forward(self, x, verbose=False):\n",
    "        x = self.conv1(x)\n",
    "        x = F.relu(x)\n",
    "        x = F.max_pool2d(x, kernel_size=2)\n",
    "        x = self.conv2(x)\n",
    "        x = F.relu(x)\n",
    "        x = F.max_pool2d(x, kernel_size=2)\n",
    "        x = x.view(-1, self.n_feature*4*4)\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        x = F.log_softmax(x, dim=1)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_list = []\n",
    "\n",
    "def train(epoch, model, perm=torch.arange(0, 784).long()):\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        # send to device\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        \n",
    "        # permute pixels\n",
    "        data = data.view(-1, 28*28)\n",
    "        data = data[:, perm]\n",
    "        data = data.view(-1, 1, 28, 28)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = F.nll_loss(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch_idx % 100 == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), loss.item()))\n",
    "            \n",
    "def test(model, perm=torch.arange(0, 784).long()):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    for data, target in test_loader:\n",
    "        # send to device\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        \n",
    "        # permute pixels\n",
    "        data = data.view(-1, 28*28)\n",
    "        data = data[:, perm]\n",
    "        data = data.view(-1, 1, 28, 28)\n",
    "        output = model(data)\n",
    "        test_loss += F.nll_loss(output, target, reduction='sum').item() # sum up batch loss                                                               \n",
    "        pred = output.data.max(1, keepdim=True)[1] # get the index of the max log-probability                                                                 \n",
    "        correct += pred.eq(target.data.view_as(pred)).cpu().sum().item()\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    accuracy = 100. * correct / len(test_loader.dataset)\n",
    "    accuracy_list.append(accuracy)\n",
    "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        test_loss, correct, len(test_loader.dataset),\n",
    "        accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train on a Fully-connected network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of parameters: 6370\n",
      "Train Epoch: 0 [0/60000 (0%)]\tLoss: 2.342890\n",
      "Train Epoch: 0 [6400/60000 (11%)]\tLoss: 0.824949\n",
      "Train Epoch: 0 [12800/60000 (21%)]\tLoss: 0.767831\n",
      "Train Epoch: 0 [19200/60000 (32%)]\tLoss: 0.468371\n",
      "Train Epoch: 0 [25600/60000 (43%)]\tLoss: 0.467844\n",
      "Train Epoch: 0 [32000/60000 (53%)]\tLoss: 0.316159\n",
      "Train Epoch: 0 [38400/60000 (64%)]\tLoss: 0.528687\n",
      "Train Epoch: 0 [44800/60000 (75%)]\tLoss: 0.326552\n",
      "Train Epoch: 0 [51200/60000 (85%)]\tLoss: 0.493075\n",
      "Train Epoch: 0 [57600/60000 (96%)]\tLoss: 0.526665\n",
      "\n",
      "Test set: Average loss: 0.3402, Accuracy: 9024/10000 (90%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "n_hidden = 8 # number of hidden units\n",
    "\n",
    "model_fnn = FC1Layer(input_size, n_hidden, output_size)\n",
    "model_fnn.to(device)\n",
    "optimizer = optim.SGD(model_fnn.parameters(), lr=0.01, momentum=0.5)\n",
    "print('Number of parameters: {}'.format(get_n_params(model_fnn)))\n",
    "\n",
    "for epoch in range(0, 1):\n",
    "    train(epoch, model_fnn)\n",
    "    test(model_fnn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train on a CNN network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of parameters: 6422\n"
     ]
    }
   ],
   "source": [
    "# Training settings \n",
    "n_features = 6 # number of feature maps\n",
    "\n",
    "model_cnn = CNN(input_size, n_features, output_size)\n",
    "model_cnn.to(device)\n",
    "optimizer = optim.SGD(model_cnn.parameters(), lr=0.01, momentum=0.5)\n",
    "print('Number of parameters: {}'.format(get_n_params(model_cnn)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 0 [0/60000 (0%)]\tLoss: 2.334307\n",
      "Train Epoch: 0 [6400/60000 (11%)]\tLoss: 1.799020\n",
      "Train Epoch: 0 [12800/60000 (21%)]\tLoss: 0.727904\n",
      "Train Epoch: 0 [19200/60000 (32%)]\tLoss: 0.241309\n",
      "Train Epoch: 0 [25600/60000 (43%)]\tLoss: 0.328741\n",
      "Train Epoch: 0 [32000/60000 (53%)]\tLoss: 0.219604\n",
      "Train Epoch: 0 [38400/60000 (64%)]\tLoss: 0.189373\n",
      "Train Epoch: 0 [44800/60000 (75%)]\tLoss: 0.297480\n",
      "Train Epoch: 0 [51200/60000 (85%)]\tLoss: 0.230633\n",
      "Train Epoch: 0 [57600/60000 (96%)]\tLoss: 0.112791\n",
      "\n",
      "Test set: Average loss: 0.2099, Accuracy: 9352/10000 (94%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(0, 1):\n",
    "    train(epoch, model_cnn)\n",
    "    test(model_cnn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fully Connected network vs. CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the same parameters, CNN out-performs FCC. Why?\n",
    "- Locality of the image\n",
    "- Stationarity in images\n",
    "\n",
    "What happens when we corrupt the image so the locality and stationarity do not hold true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x864 with 20 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "perm = torch.randperm(784)\n",
    "# Select 784 because 784 - 28 * 28 = image size\n",
    "plt.figure(figsize=(16, 12))\n",
    "for i in range(10):\n",
    "    image, _ = train_loader.dataset.__getitem__(i)\n",
    "    # permute pixels\n",
    "    image_perm = image.view(-1, 28*28).clone()\n",
    "    image_perm = image_perm[:, perm]\n",
    "    image_perm = image_perm.view(-1, 1, 28, 28)\n",
    "    plt.subplot(4, 5, i + 1)\n",
    "    plt.imshow(image.squeeze().numpy())\n",
    "    plt.axis('off')\n",
    "    plt.subplot(4, 5, i + 11)\n",
    "    plt.imshow(image_perm.squeeze().numpy())\n",
    "    plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of parameters: 6370\n",
      "Train Epoch: 0 [0/60000 (0%)]\tLoss: 2.424109\n",
      "Train Epoch: 0 [6400/60000 (11%)]\tLoss: 1.025979\n",
      "Train Epoch: 0 [12800/60000 (21%)]\tLoss: 0.594391\n",
      "Train Epoch: 0 [19200/60000 (32%)]\tLoss: 0.378778\n",
      "Train Epoch: 0 [25600/60000 (43%)]\tLoss: 0.591758\n",
      "Train Epoch: 0 [32000/60000 (53%)]\tLoss: 0.561207\n",
      "Train Epoch: 0 [38400/60000 (64%)]\tLoss: 0.422802\n",
      "Train Epoch: 0 [44800/60000 (75%)]\tLoss: 0.522755\n"
     ]
    }
   ],
   "source": [
    "n_hidden = 8    # number of hidden units\n",
    "\n",
    "model_fnn = FC1Layer(input_size, n_hidden, output_size)\n",
    "model_fnn.to(device)\n",
    "optimizer = optim.SGD(model_fnn.parameters(), lr=0.01, momentum=0.5)\n",
    "print('Number of parameters: {}'.format(get_n_params(model_fnn)))\n",
    "\n",
    "for epoch in range(0, 1):\n",
    "    train(epoch, model_fnn, perm)\n",
    "    test(model_fnn, perm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training settings \n",
    "n_features = 6 # number of feature maps\n",
    "\n",
    "model_cnn = CNN(input_size, n_features, output_size)\n",
    "model_cnn.to(device)\n",
    "optimizer = optim.SGD(model_cnn.parameters(), lr=0.01, momentum=0.5)\n",
    "print('Number of parameters: {}'.format(get_n_params(model_cnn)))\n",
    "\n",
    "for epoch in range(0, 1):\n",
    "    train(epoch, model_cnn, perm)\n",
    "    test(model_cnn, perm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
